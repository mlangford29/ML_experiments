{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d21e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from optuna.samplers import RandomSampler\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75f5c91-60f7-49b2-85b1-3dff2769c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, scoring_metric='roc_auc'):\n",
    "    \"\"\"Objective function for Optuna to optimize.\"\"\"\n",
    "    \n",
    "    # suggest parameters for classification dataset\n",
    "    n_samples = trial.suggest_int('n_samples', 100, 1000000, log=True)\n",
    "    n_features = trial.suggest_int('n_features', 3, 20)\n",
    "    n_informative = trial.suggest_int('n_informative', 1, n_features - 2)\n",
    "    n_redundant = trial.suggest_int('n_redundant', 0, n_features - n_informative - 1)\n",
    "    n_repeated = n_features - n_informative - n_redundant\n",
    "    \n",
    "    # ensure the condition: n_classes(2) * n_clusters_per_class <= 2**n_informative\n",
    "    max_clusters = min(5, (2 ** n_informative) // 2)\n",
    "    n_clusters_per_class = trial.suggest_int('n_clusters_per_class', 1, max_clusters)\n",
    "    \n",
    "    # class weights\n",
    "    weights = [trial.suggest_uniform('weights', 0.01, 0.99)]\n",
    "    class_sep = trial.suggest_loguniform('class_sep', 0.01, 10.0)\n",
    "    \n",
    "    # generate dataset\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        n_informative=n_informative,\n",
    "        n_redundant=n_redundant,\n",
    "        n_repeated=n_repeated,\n",
    "        n_classes=2,\n",
    "        n_clusters_per_class=n_clusters_per_class,\n",
    "        weights=weights,\n",
    "        class_sep=class_sep,\n",
    "        flip_y=0.01,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # define LightGBM classifier\n",
    "    model = lgb.LGBMClassifier(verbose=-1)\n",
    "    \n",
    "    # perform 5-fold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    score = cross_val_score(model, X, y, cv=kf, scoring=scoring_metric).mean()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb12a6e9-5da0-4fd4-a529-7f6f64fdfe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(trials=1000, scoring_metric='roc_auc', max_hours=None):\n",
    "    \"\"\"\n",
    "    Runs the Optuna experiment up to 'trials' iterations OR \n",
    "    until 'max_hours' hours have elapsed (whichever is reached first).\n",
    "\n",
    "    :param trials: Maximum number of trials.\n",
    "    :param scoring_metric: Scoring metric for cross-validation.\n",
    "    :param max_hours: If provided, time limit in hours for the experiment.\n",
    "    :return: Optuna study object.\n",
    "    \"\"\"\n",
    "    optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "    \n",
    "    # create the study\n",
    "    study = optuna.create_study(sampler=RandomSampler(), direction='maximize')\n",
    "    \n",
    "    # convert hours to seconds for the 'timeout' parameter if needed\n",
    "    timeout_sec = None\n",
    "    if max_hours is not None:\n",
    "        timeout_sec = int(max_hours * 3600)\n",
    "    \n",
    "    # run optimization\n",
    "    study.optimize(\n",
    "        lambda trial: objective(trial, scoring_metric=scoring_metric),\n",
    "        n_trials=trials,\n",
    "        timeout=timeout_sec,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "    \n",
    "    # save results to CSV\n",
    "    results = study.trials_dataframe()\n",
    "    results.to_csv('simulation_results.csv', index=False)\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deea0ee-c12d-4779-a82c-755dd0aad80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_analysis(study):\n",
    "    \"\"\"\n",
    "    Runs a SHAP analysis on the results of the study, using a surrogate model\n",
    "    (LGBM Regressor) trained on the param-values -> final score relation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert study results to DataFrame\n",
    "    results_df = study.trials_dataframe()\n",
    "    \n",
    "    # identify parameter columns (those that start with 'params_')\n",
    "    param_cols = [col for col in results_df.columns if col.startswith('params_')]\n",
    "    \n",
    "    if not param_cols:\n",
    "        print(\"No parameter columns found in study DataFrame.\")\n",
    "        return\n",
    "\n",
    "    X = results_df[param_cols].copy()\n",
    "    y = results_df['value'].copy()\n",
    "    \n",
    "    # fit surrogate model\n",
    "    surrogate = lgb.LGBMRegressor(random_state=42)\n",
    "    surrogate.fit(X, y)\n",
    "    \n",
    "    # explain predictions using SHAP\n",
    "    explainer = shap.Explainer(surrogate, X)\n",
    "    shap_values = explainer(X)\n",
    "    \n",
    "    # SHAP plots\n",
    "    print(\"Generating SHAP plots ...\")\n",
    "    shap.plots.beeswarm(shap_values, show=True)\n",
    "    shap.plots.bar(shap_values, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71278cfd-c00b-4f05-bda8-9c6207371344",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = run_experiment(trials=10_000, max_hours=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421f7bf3-e7cc-4c54-b9c2-500e1f3ecd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after the study is done, perform SHAP analysis\n",
    "shap_analysis(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc15a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "ov.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cc4b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ov.plot_contour(study, params=[\"class_sep\", \"weights\", \"n_samples\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
